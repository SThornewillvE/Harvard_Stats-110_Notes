{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 17: Memorylessness Cont. and Moment Generating Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 1. Memorylessness Continued\n",
    "\n",
    "We will consider the question about the phones from last time.\n",
    "\n",
    "Let F be the CDF of X. Then $P(X > x) = 1 - F(X) = G(X)$\n",
    "\n",
    "The memorylessness property is that $4G(s + t) = G(s)G(t)$. This means we need to find a function that satisfies G.\n",
    "\n",
    "We can experiment with it and find that if $s = t$ that $G(2t) = G(t)^2$ and more generally $G(kt) = G(t)^k$.\n",
    "\n",
    "We can also find that $G(t * 0.5) ? G(t)^0.5$\n",
    "\n",
    "If $s = 1$ then $G(t) = G(1)^t = e^{x \\textrm{ln}(G(1))}$\n",
    "\n",
    "If we consider this to be some constant $-\\lambda$,\n",
    "\n",
    "$$\\therefore G(x) = e^{-\\lambda x}$$\n",
    "\n",
    "This is why exponential functions are memoryless. (On an intuitive level what this means is that if you try to find a probability after a certain point, you need to renormalise the distribution which will return the original exponential distribution.)\n",
    "\n",
    "Hence, the expected lifetime of a value of the phone is  $2 + 4 = 6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 2. Moment Generating Functions\n",
    "\n",
    "Random variables have a moment generating function (MGF) $M(t) = E(e^{tx})$. \n",
    "\n",
    "These are a function of t and have a finite region.\n",
    "\n",
    "Why is it moment generating? \n",
    "\n",
    "$E(e^{tx} = E(\\sum_0^\\infty \\frac{x^n t^n}{n!})$, then from linearity $E(e^{tx}) = \\sum_0^\\infty \\frac{E(x^n) t^n}{n!}$ where $E(x^n)$ is the nth moment!\n",
    "\n",
    "1. The nth moment is the coefficient $\\frac{t^n}{n!}$ in the Taylor series of M, i.e. $E(X^n) = M^{(n)}(0)$\n",
    "2. M(t) determines the distribution, i.e. if X and Y have the same moments then they always belong to the same CDF\n",
    "3. Makes sums easier to handle given X and Y are independent i.e. $E(e^{t(x+y)}) = E(e^{tx})E(e^{ty})$\n",
    "\n",
    "### Point 2.2 MGF of Bernouli Dist.\n",
    "\n",
    "Let $X \\sim Bernouli(p)$, then $M(t) = E(e^{tX}) = pe^t + q$\n",
    "\n",
    "$\\therefore M(t) = (pe^t + q)^n$\n",
    "\n",
    "### Point 2.3 MGF of Std. Norm. Dist.\n",
    "\n",
    "let $X \\sim N(0, 1)$\n",
    "\n",
    "Then, $M(t) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} e^{tz-\\frac{z^2}{2}} dz$\n",
    "\n",
    "$\\therefore M(t) = e^{\\frac{t^2}{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 3. Laplace's Rule of Succession\n",
    "\n",
    "\"What is the probability that the sun will rise tomorrow given that it has always risen so far?\"\n",
    "\n",
    "Let X be the event that the sun rises and that it is bernoili distributed. The events of the sun rising on the ith day is $X_i$.\n",
    "\n",
    "Let the parameter p be distributed $p \\sim \\textrm{Unif}(0, 1)$ and let the sum of our results so far be $S_n = X_1 + ... + X_n$\n",
    "\n",
    "The likelihood of each $S_n$ given $p$ is bernouli distributed.\n",
    "\n",
    "What is the posterior? ($P(p | S_n)$)?\n",
    "\n",
    "$$P(p | S_n) = \\frac{P(S_n = K | p) f(p)}{P(S_n = k)} = \\frac{P(S_n = K | p) f(p)}{\\int_0^1 P(S_n = k | p)f(p) dp}$$\n",
    "\n",
    "$$ \\therefore P(X_{n+1} = 1 | S_n = n) = \\int _0^1 (n+1)p^np dp = \\frac{n+1}{n+2}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
