{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 20: Multinomial Distribution and Joint Distributions Continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 1. Joint distributions continnued\n",
    "\n",
    "Problem: Find the espectation value of $|Z_1 - Z_2|$ given that $Z_i \\sim N(0, 1)$ and the two are independent.\n",
    "\n",
    "To find this we can simply multiply the MGFs of the two together $e^{\\mu_1 t + \\frac{\\sigma_1^2 t^2}{2}} e^{\\mu_2 t + \\frac{\\sigma_2^2 t^2}{2}} = e^{(\\mu_1 + \\mu_2) t + \\frac{(\\sigma_1^2 + \\sigma_2^2) t^2}{2}}$\n",
    "\n",
    "This means that $Z_1 - Z_2 \\sim N(0, 2) = \\sqrt2Z, Z \\sim N(0, 1)$.\n",
    "\n",
    "We can pull out the root two by linearity, $\\sqrt2 \\int_{-\\infty}^{\\infty} |z| \\frac{1}{\\sqrt{2\\pi}} e^{\\frac{-z^2}{2}} dz$\n",
    "\n",
    "Note that this is an odd function, meaning we can ingegrate from 0 to infty and we can also pull out constants again $\\sqrt2 \\frac{1}{\\sqrt{2\\pi}} \\int_{0}^{\\infty} z  e^{\\frac{-z^2}{2}} dz$\n",
    "\n",
    "We can then use u substitution to find that this is equal to $\\frac{\\sqrt2}{\\pi}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 2. Multinomial Distribution\n",
    "\n",
    "Generalisation of the Binomial Distribution, denoted by $\\vec X \\sim \\textrm{Mult}(n, \\vec p)$. X and p are now vectors with k dimensions.\n",
    "\n",
    "The probabilities in $\\vec p$ must all be larger than 0 and must add to 1.\n",
    "\n",
    "Story: We have n objects, all are independent, they are split into k categories where the probability of being that category is denoted by $p_j$ and $x_j$ being the number of objects in category j.\n",
    "\n",
    "PMF:\n",
    "\n",
    "$$P(X_1=n_1, ..., X_k = n_k) = \\frac{n!}{\\prod_{i=1}^k n_i!} \\prod_{i=1}^k p_i^{n_i}, \\sum_{i=1}^k n_i = n$$\n",
    "\n",
    "Note that the marginal distribution for any single dimension is simply the binomal with X and p being the associated values for the relevant dimension.\n",
    "\n",
    "### Point 2.2 Lumping property\n",
    "\n",
    "What's really nice about the binomial distribution is if we have 10 categories, we can reduce the number of categories all we want. The relevant $x_j$ and probability values will just be summed together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 3. Cauchy Interview Problem\n",
    "\n",
    "Not studying this further to save time and because I don't think I'll ever meet this in real life outside of maybe physics and physical chemistry. (See spectroscopy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
